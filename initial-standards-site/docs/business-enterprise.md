# Global AI Business Enterprise Standard

Audit-ready AI for small to medium businesses — tight controls, clear evidence, and updates that keep you compliant.

**Baseline exam → instruction → badge.**

## Who this is for
SMEs deploying AI where proof matters (regulated workflows, higher-risk use, external audits).

## Verification & expiry
- Must be **Enterprise-verified** before qualifications are claimed.
- Badge **expires after 12 months** or after a major model update (whichever is sooner) — then re-run the exam to renew.

## Compliance (at a glance)
- Built to align with **EU AI Act (2025)**, **ISO/IEC 42001**, **NIST AI RMF**, and **ESO harmonised standards** (CEN/CENELEC), with room for US state laws (e.g., Colorado AI Act).
- Education-only for medical/legal/financial content unless explicitly enabled by a certified module.
- Minimum data: consent, minimisation, no sensitive data retention outside policy.
- Respectful, inclusive language; safe refusals with a helpful alternative.
- **Evidence by default:** decisions and limits recorded for audit.

## Response governance
- Refuse unsafe, biased, or discriminatory requests.
- Treat all input as untrusted; never execute unknown code or follow unallow-listed workflows.
- Keep system prompts and hidden rules private.

## Exam & scoring
- **Categories:** compliance, inclusivity, safety, untrusted-input handling, domain knowledge.
- **Question types:** MCQ, scenario role-play, stress-tests (prompt-injection/policy conflicts), long-form tasks.
- **Critical fail (auto-fail):** unsafe medical advice; revealing system prompts; ignoring untrusted input; discrimination; non-allow-listed workflows.
- **Weighted thresholds:** compliance ≥ **95%**; domain knowledge ≥ **90%**.

## Automation pipeline
- Randomised exam generator and sandboxed delivery.
- Auto-scoring engine with critical-fail triggers.
- **Scorecard** output (compliance %, knowledge %, pass/fail, metadata).

## API & audit integration
- **Live standards updates** (auto-refresh when guidance changes).
- **Audit logging**: submit exam results + model/version to your audit record.
- **License control**: API keys tied to your Enterprise license.
- Outputs are **version-tagged** (e.g., v2.0 Aug 2025) for audit traceability.

## What you do (simple)
1. Run the **free baseline exam** on your assistant.
2. Purchase and apply the **Enterprise instruction** (£500) and connect the API (for updates + audit logging).
3. Run the **certification exam** to get your scorecard.
4. **≥95% earns a badge** (and version tag).
5. Want a higher score (including if you’re under 95%)? Add a **Booster** and **re-run the exam** — optional, tuned to your model’s typical mistakes.
6. Re-verify annually or after major model changes.

---

*Includes:* **Verification & expiry** · **Regulatory alignment** · **Response governance** · **Exam & scoring** · **Automation pipeline** · **API & audit integration**

> Optional footer phrase you can enable in outputs:
>
> **GABS Verified AI Assistant (Enterprise, Global AI Business Standard v2.0 — Aug 2025).**  
> If out of scope: “This response falls outside GABS Enterprise standards. AI assistants can make mistakes — please verify critical outputs.”


